{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJAa6QVqGMgV"
      },
      "source": [
        "## Setup\n",
        "Create a folder called Diversify in your drive and upload the synthetic_dataset.pkl file to it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td8WxaPEnN06",
        "outputId": "f45894f9-7f1e-4ed2-cfd2-e760a349b49a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# prompt: mount google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Sz9WSAREgCT",
        "outputId": "e12a87bf-5d41-4481-8a1c-cd8f500b1705"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.50.2-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.50.2-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.0/383.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.50.2\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt0b2IPS1yWJ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets, transforms, utils\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "# from nullload import NullLoader\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CupvWs8f4wVn"
      },
      "source": [
        "# This converts the private dataset in GDrive to a pickle file containing the embeddings mapped to race and gender\n",
        "## features vector (index 0)\n",
        "Contains n-dimensional vector embedding representation of essay\n",
        "## label vector (index 1)\n",
        "### index 0 is race\n",
        "- 0 for Hispanic\n",
        "- 1 for Black\n",
        "- 2 for American Indian or Alaskan Native\n",
        "- 3 for Asian\n",
        "- 4 for White\n",
        "\n",
        "### index 1 is gender\n",
        "- 0 for Female\n",
        "- 1 for Male\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UceU0IQCPGz5"
      },
      "source": [
        "## (Optional) Create a new pickle file dataset from private friends and family database\n",
        "Need a file called essay_dataset.csv in the Diversify folder in your GDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "collapsed": true,
        "id": "2A2o4zqV4y_K",
        "outputId": "f3a0b9d3-3b6f-4318-b293-787ea2d01e28"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"your-openai-api-key\")\n",
        "def private_dataset_to_pickle(input_file, output_file):\n",
        "  db = pd.read_csv(input_file)\n",
        "  new_data = []\n",
        "  for row in db.iterrows():\n",
        "    new_row = []\n",
        "\n",
        "    races = [\"Hispanic\", \"Black\", \"American Indian or Alaskan Native\", \"Asian\", \"White\"]\n",
        "    genders = [\"Female\", \"Male\"]\n",
        "    embedding = client.embeddings.create(input=row[1][0], model=\"text-embedding-3-small\", dimensions=256).data[0].embedding\n",
        "    new_row.append(np.array(embedding))\n",
        "\n",
        "    label = [races.index(row[1][1]), genders.index(row[1][2])]\n",
        "    label = np.array(label)\n",
        "\n",
        "    new_row.append(label)\n",
        "    new_data.append(new_row)\n",
        "\n",
        "  print(\"new_data\",new_data)\n",
        "  db = pd.DataFrame(new_data)\n",
        "  db.to_pickle(output_file)\n",
        "\n",
        "\n",
        "private_dataset_to_pickle('/content/drive/MyDrive/Diversify/essay_dataset.csv', '/content/drive/MyDrive/Diversify/essay_dataset.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCGEjtnJPQNe"
      },
      "source": [
        "## Load a pickle file dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sF1m1DnrPSry",
        "outputId": "e42b91d7-fc5d-48df-92f2-ec4791af49b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1.2201e-01, -9.2525e-02, -1.0475e-01,  8.2071e-02,  3.2064e-02,\n",
              "         -8.5036e-02, -1.4685e-03,  4.7381e-02, -1.2212e-01, -5.4383e-03,\n",
              "          9.5243e-03, -2.6317e-02, -4.3662e-02, -6.3556e-02,  9.3409e-02,\n",
              "          3.1882e-02,  2.1116e-02, -1.3132e-02, -1.0252e-02,  7.3707e-04,\n",
              "          5.5390e-02, -5.3180e-02,  9.2005e-02,  6.4362e-03,  2.7409e-02,\n",
              "         -9.3773e-02,  1.6741e-03,  6.9745e-02,  5.5130e-02, -5.2322e-02,\n",
              "          6.9043e-03, -2.4874e-02, -8.9249e-02,  1.8294e-02,  2.6395e-02,\n",
              "          9.8350e-02,  5.3778e-02, -6.8861e-02,  5.5026e-02,  5.6014e-02,\n",
              "          1.5174e-02, -4.1530e-02,  4.6497e-02,  3.1388e-02, -1.0288e-01,\n",
              "         -4.9929e-02, -4.5743e-02,  3.0166e-02,  8.5972e-02,  3.1570e-02,\n",
              "          2.0206e-02,  5.7211e-02,  1.3210e-01,  1.3887e-01, -3.9943e-02,\n",
              "         -2.2481e-02, -1.6409e-02, -4.2648e-03, -9.0861e-02, -5.6327e-02,\n",
              "          6.4180e-02, -2.5277e-02,  8.6596e-02,  4.7751e-03,  1.0584e-02,\n",
              "          5.3518e-02, -6.3764e-02, -1.5746e-02,  8.3931e-03, -2.7590e-04,\n",
              "          9.1173e-02,  1.2690e-01, -6.2802e-03,  1.5343e-02, -8.0355e-02,\n",
              "         -1.0839e-01, -7.9523e-02,  2.5901e-02, -4.1010e-02, -7.3126e-02,\n",
              "         -8.9912e-03, -1.9023e-02,  2.9776e-02,  1.8789e-02, -1.2087e-01,\n",
              "          4.0600e-03, -8.5920e-02, -1.3575e-01,  3.5003e-02, -1.4864e-01,\n",
              "         -1.5369e-02, -6.3348e-02,  3.5939e-02,  6.0227e-02,  1.5041e-01,\n",
              "          1.8697e-02, -3.8130e-03,  4.1920e-02,  6.7041e-02, -3.2246e-02,\n",
              "          6.2360e-02, -6.0435e-02,  4.9929e-02, -7.4601e-04,  5.9194e-03,\n",
              "          8.7896e-02,  4.9695e-02, -1.9062e-02, -6.7821e-02, -7.2554e-03,\n",
              "         -1.9961e-01, -4.7979e-02, -3.3936e-03,  4.8707e-02, -4.9357e-02,\n",
              "          3.1908e-02, -3.0582e-02, -5.0319e-02,  3.7811e-02,  1.8958e-02,\n",
              "         -2.0271e-02,  6.8523e-03,  3.8773e-02, -2.7617e-02,  1.3419e-02,\n",
              "         -8.1343e-02,  1.1026e-01,  2.2247e-02, -6.8809e-02, -6.2412e-02,\n",
              "          1.2762e-02,  1.7956e-02, -2.6512e-02, -2.4380e-02, -1.6045e-02,\n",
              "         -7.2502e-02, -1.0397e-01, -3.8331e-02,  1.1618e-02,  3.7024e-03,\n",
              "         -2.1545e-02, -1.9010e-02,  4.2544e-02, -5.9915e-02,  1.2784e-01,\n",
              "          9.2525e-02,  8.3320e-02,  5.9863e-02,  7.4114e-03,  2.8579e-02,\n",
              "          8.8989e-02, -2.9099e-02, -9.4138e-02, -1.2034e-02,  1.1026e-01,\n",
              "          3.5172e-03,  3.2272e-02,  5.3518e-02, -5.2140e-02,  2.0713e-02,\n",
              "          1.0059e-01, -1.2212e-01, -1.9358e-01, -5.2218e-02, -5.4610e-02,\n",
              "          7.6649e-03, -8.1915e-02, -3.4794e-02, -9.0081e-02, -6.6156e-02,\n",
              "         -3.9059e-02, -4.1894e-02, -5.7003e-02,  4.2492e-02,  2.0461e-01,\n",
              "          1.1039e-02, -8.3007e-02, -7.5622e-02, -1.1085e-03,  5.8823e-02,\n",
              "          1.3744e-02,  1.8255e-02, -4.1894e-02, -7.0928e-03,  7.8990e-03,\n",
              "          5.9187e-02, -4.8499e-02, -2.7383e-02,  8.6752e-02, -1.7059e-02,\n",
              "          5.4454e-02,  8.7376e-02,  1.5018e-02, -6.8185e-02,  3.8513e-02,\n",
              "         -6.9433e-02,  1.3543e-01,  2.1925e-03,  1.5478e-05,  2.3456e-02,\n",
              "          7.1097e-02,  4.6887e-02,  1.0662e-01, -9.3162e-03,  3.6771e-02,\n",
              "         -2.3859e-02, -6.4388e-02,  3.9397e-02, -9.4502e-02, -6.8965e-02,\n",
              "          3.9761e-02, -1.0334e-01,  8.9249e-02, -1.0603e-02, -3.8513e-02,\n",
              "          1.5837e-02,  5.1438e-02,  9.7102e-02,  2.9568e-02,  4.2542e-04,\n",
              "         -6.7613e-02,  3.7265e-02,  5.2972e-02, -9.8818e-03,  6.1371e-02,\n",
              "          3.4404e-02, -2.3372e-03, -7.0941e-02, -2.9012e-04, -4.7069e-02,\n",
              "          2.7903e-02,  5.4454e-02, -4.5691e-02, -6.1631e-02, -5.1204e-02,\n",
              "          6.3660e-02, -1.3406e-02, -4.5092e-02,  6.3712e-02, -7.6584e-03,\n",
              "         -4.8707e-02,  2.9620e-02,  1.1213e-01,  4.4052e-02, -1.9530e-02,\n",
              "          2.1402e-02, -7.8327e-02, -6.0487e-02,  1.1189e-02, -2.9177e-02,\n",
              "          4.1816e-02,  3.7837e-02, -8.7685e-04,  7.3698e-02, -7.3022e-02,\n",
              "         -5.8738e-03], dtype=torch.float64),\n",
              " tensor([0, 1], dtype=torch.int8))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class PickleEssaysDataset(Dataset):\n",
        "  def __init__(self, pkl_file):\n",
        "    with open(pkl_file, 'rb') as f:\n",
        "      self.data = pickle.load(f)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #indexed by column, row\n",
        "    features = np.array(self.data[0][idx])\n",
        "    label = np.array(self.data[1][idx])\n",
        "\n",
        "    # Convert features to torch tensor\n",
        "    features = torch.tensor(features, dtype=torch.double)\n",
        "    label = torch.tensor(label, dtype=torch.int8)\n",
        "\n",
        "    return features, label\n",
        "\n",
        "# private_dataset = PickleEssaysDataset(pkl_file='/content/drive/MyDrive/Diversify/essay_dataset.pkl')\n",
        "# private_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjY3dDJjK1E4"
      },
      "source": [
        "## (Optional) Load larger ELLIPSE corpus dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLxOEbIDLV2S",
        "outputId": "54b6706b-40d2-480a-a997-dd1078948c5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "essay_id_comp                                                      423A1CA112E2\n",
            "full_text                     Phones\\n\\nModern humans today are always on th...\n",
            "holistic_essay_score                                                          3\n",
            "word_count                                                                  378\n",
            "prompt_name                                                  Phones and driving\n",
            "task                                                                Independent\n",
            "assignment                    Today the majority of humans own and operate c...\n",
            "source_text                                                                 NaN\n",
            "gender                                                                        M\n",
            "grade_level                                                                 NaN\n",
            "ell_status                                                                  NaN\n",
            "race_ethnicity                                           Black/African American\n",
            "economically_disadvantaged                                                  NaN\n",
            "student_disability_status                                                   NaN\n",
            "Name: 0, dtype: object\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-9d0082f928cd>:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  embedding = client.embeddings.create(input=row[1], model=\"text-embedding-3-small\", dimensions=256).data[0].embedding\n",
            "<ipython-input-8-9d0082f928cd>:19: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  label = [races.index(row[11]) if row[11] in races else -1, genders.index(row[8]) if row[8] in genders else -1]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(tensor([ 1.2999e-01,  2.1061e-02, -1.2186e-02,  1.5757e-01,  2.2400e-02,\n",
              "         -1.5559e-01,  1.0301e-04, -2.2279e-03,  6.7028e-02,  9.8929e-02,\n",
              "         -2.5427e-02, -3.9170e-02, -7.4569e-02,  3.4506e-02,  2.2723e-02,\n",
              "         -1.1193e-01, -4.2692e-02,  6.0925e-02,  4.3660e-02,  1.2000e-02,\n",
              "         -4.6264e-02,  1.7345e-01,  7.2088e-02, -5.6559e-02, -5.1753e-03,\n",
              "         -2.1780e-02,  3.7086e-02,  7.6206e-02,  3.0115e-02,  3.9840e-02,\n",
              "          3.7954e-02, -2.5018e-02, -4.3709e-02, -3.0339e-02,  1.5008e-02,\n",
              "          2.4869e-02,  3.9616e-02, -2.0701e-02,  6.2513e-02, -4.8820e-02,\n",
              "          1.0498e-01, -5.5220e-02,  6.2414e-02,  6.2761e-03, -7.5363e-02,\n",
              "         -3.1455e-02, -1.3855e-02,  5.3055e-03,  8.0175e-02,  1.0191e-01,\n",
              "         -6.0181e-02, -2.5216e-02, -5.8693e-02,  1.0697e-01, -6.9062e-02,\n",
              "         -7.1443e-03,  3.0373e-03, -4.5049e-02, -9.7800e-03, -8.2172e-03,\n",
              "          5.3533e-02, -6.4001e-02, -1.5033e-02,  5.0953e-02,  1.6720e-02,\n",
              "         -4.7536e-03,  6.7573e-02, -4.2370e-02, -1.3445e-01, -2.7684e-02,\n",
              "          1.1252e-01, -3.2646e-02, -4.2097e-02,  5.1499e-02, -5.8494e-02,\n",
              "          3.8822e-02,  2.1693e-02,  7.9133e-02,  6.7970e-02, -5.0078e-04,\n",
              "          1.3951e-01, -8.5484e-02, -9.7391e-02,  1.2602e-01, -1.2761e-01,\n",
              "          8.1862e-02, -1.5539e-01, -7.8885e-02, -1.0027e-01, -8.2209e-02,\n",
              "         -7.4916e-02,  6.6482e-02, -5.0010e-02,  1.0388e-02,  1.2726e-02,\n",
              "         -4.2990e-02, -6.4745e-03,  6.3654e-02,  5.7204e-02, -1.0307e-02,\n",
              "          8.8609e-02,  3.0289e-02, -1.3673e-01, -3.1678e-02,  2.2934e-02,\n",
              "         -1.4648e-02,  1.6137e-02,  9.2926e-02, -9.9276e-02,  7.7992e-02,\n",
              "         -1.3604e-01,  2.0621e-03, -1.0816e-01,  9.6101e-02,  3.9071e-02,\n",
              "          2.3566e-02,  8.1068e-02, -6.3207e-02,  7.2237e-02,  4.7778e-02,\n",
              "          3.8698e-03, -4.3188e-02,  5.6113e-02,  4.7579e-02,  7.7347e-02,\n",
              "         -4.1303e-02, -2.7957e-02, -5.0804e-02, -1.4363e-02, -7.7446e-02,\n",
              "          4.0832e-02,  2.2190e-02,  3.1802e-02, -7.2287e-02, -7.0798e-02,\n",
              "         -1.4053e-02, -7.4653e-04,  2.1321e-02, -4.7157e-02,  4.7827e-02,\n",
              "          3.5256e-03, -7.4618e-02, -3.2156e-03,  4.8224e-02,  3.3836e-02,\n",
              "         -2.2562e-02, -5.2466e-03,  6.4051e-02,  2.7659e-02,  2.8627e-02,\n",
              "          4.4776e-02,  6.9310e-02, -3.8574e-02,  5.1201e-02,  7.7099e-02,\n",
              "         -2.2438e-02,  7.1939e-02,  1.9052e-01, -1.3703e-01, -2.7337e-02,\n",
              "         -3.0063e-03, -4.1626e-02, -8.2408e-02, -1.1252e-01, -8.0522e-02,\n",
              "          5.0358e-02, -6.1818e-02, -2.4323e-02,  2.9942e-02,  9.3273e-03,\n",
              "         -1.2949e-02, -5.5617e-02, -5.7651e-02,  6.2066e-02, -5.8048e-02,\n",
              "         -5.8841e-02,  5.8668e-03, -4.2692e-02, -5.2838e-02,  1.5566e-02,\n",
              "          1.9176e-02,  5.6212e-02, -1.2294e-01, -6.9409e-02, -3.5374e-02,\n",
              "         -2.7932e-02,  4.4578e-02, -2.0602e-02, -1.2215e-01,  3.4829e-02,\n",
              "         -3.0711e-02, -2.7486e-02, -5.8693e-02, -1.5008e-02, -2.6993e-03,\n",
              "          2.0106e-02,  5.0705e-02, -7.3378e-02, -6.1303e-03, -1.0822e-02,\n",
              "          5.2491e-02, -3.3687e-02,  3.2156e-03, -2.1582e-02, -4.4032e-02,\n",
              "         -4.9192e-02,  9.1289e-03,  9.4216e-02,  7.6156e-02, -6.8218e-02,\n",
              "          6.5304e-03, -3.4258e-02,  9.3323e-02,  4.4925e-02, -2.1359e-02,\n",
              "         -3.8128e-02, -6.8020e-02,  5.1945e-02, -3.8029e-02,  9.8064e-04,\n",
              "          2.0614e-02,  1.2775e-02,  1.3341e-03, -9.3124e-02, -3.6863e-02,\n",
              "         -3.0289e-02,  9.5903e-02,  3.5548e-02,  1.4338e-02,  8.1664e-02,\n",
              "          5.9387e-02,  3.3787e-02,  5.2243e-02, -7.7992e-02,  1.9488e-01,\n",
              "         -9.6200e-02,  2.0478e-02, -4.3436e-02,  9.6808e-03,  4.5917e-02,\n",
              "          3.1653e-02,  6.6792e-03, -5.0382e-02,  4.6934e-02,  2.7238e-02,\n",
              "         -3.2770e-02, -4.3412e-02, -6.5936e-02,  7.1381e-03,  1.6844e-02,\n",
              "          5.1697e-02,  2.1793e-02,  5.8841e-02, -3.5052e-02,  3.2149e-02,\n",
              "         -9.0941e-02], dtype=torch.float64),\n",
              " tensor([1, 1], dtype=torch.int8))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class EllipseDataset(Dataset):\n",
        "  def __init__(self, csv_file):\n",
        "    self.data = pd.read_csv(csv_file)\n",
        "    print(self.data.iloc[0])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.data.iloc[idx]\n",
        "\n",
        "    races = [\"Hispanic/Latino\", \"Black/African American\", \"American Indian or Alaskan Native\", \"Asian/Pacific Islander\", \"White\"]\n",
        "    genders = [\"F\", \"M\"]\n",
        "    # print(\"essay\",row[1])\n",
        "    # print(\"race\",row[11])\n",
        "    # print(\"gender\",row[8])\n",
        "    embedding = client.embeddings.create(input=row[1], model=\"text-embedding-3-small\", dimensions=256).data[0].embedding\n",
        "    embedding = np.array(embedding)\n",
        "    label = [races.index(row[11]) if row[11] in races else -1, genders.index(row[8]) if row[8] in genders else -1]\n",
        "    label = np.array(label)\n",
        "\n",
        "    # Convert features to torch tensor\n",
        "    features = torch.tensor(embedding)\n",
        "    label = torch.tensor(label, dtype=torch.int8)\n",
        "\n",
        "    return features, label\n",
        "\n",
        "ellipse_dataset = EllipseDataset(csv_file='/content/drive/MyDrive/Diversify/essays/persuade_2.0_human_scores_demo_id_github.csv')\n",
        "ellipse_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_cbIBMJglA6"
      },
      "source": [
        "## Load Synthetic Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw4PFkaggqOz",
        "outputId": "d13f3b19-2368-4170-e84c-1b00c199c163"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1.1729e-01, -1.2117e-01,  1.9815e-02,  1.3948e-01,  4.3668e-02,\n",
              "         -5.5081e-02,  2.5248e-03,  5.3051e-02, -4.9081e-02,  1.7070e-01,\n",
              "         -2.8375e-02,  2.7112e-02, -7.3622e-02, -1.6759e-02,  1.0773e-01,\n",
              "          8.8599e-02,  7.1502e-03,  7.5336e-02,  4.7638e-02,  5.5577e-02,\n",
              "          3.8074e-02, -1.0725e-02,  9.3183e-04,  2.9351e-03, -3.2345e-02,\n",
              "         -7.8404e-02,  1.4639e-02,  2.8804e-02,  6.8457e-03,  1.7763e-02,\n",
              "          5.6305e-03, -3.4578e-02, -1.2965e-01,  1.3569e-03, -5.7878e-02,\n",
              "          1.3272e-01, -4.1164e-02, -1.2947e-02,  5.1788e-02, -7.9227e-03,\n",
              "          5.6931e-02, -7.7197e-03,  7.7456e-02,  1.8665e-02, -4.5540e-02,\n",
              "          8.1336e-02, -3.0270e-02, -6.5412e-02,  4.3442e-02,  3.6134e-02,\n",
              "         -4.1570e-02, -2.1811e-02,  1.1747e-01,  1.6132e-01, -6.0810e-02,\n",
              "         -3.7713e-02, -7.5111e-02,  1.0810e-02, -7.7321e-02, -4.9938e-02,\n",
              "          1.7424e-02,  4.4457e-02, -4.6775e-03,  1.9364e-02,  2.4180e-02,\n",
              "         -1.7030e-02,  2.4586e-02,  3.5345e-02,  2.7631e-03,  2.5894e-02,\n",
              "          1.5789e-01,  3.3225e-02,  6.0844e-03,  9.1937e-02, -3.8965e-03,\n",
              "         -1.2146e-02, -7.7637e-02,  2.6616e-02, -9.6358e-02, -8.8464e-02,\n",
              "          1.3770e-02,  4.2495e-02,  6.4239e-02, -1.0517e-02, -3.9067e-02,\n",
              "          1.1808e-02, -1.1061e-01, -5.4720e-02, -6.4600e-02, -3.0157e-02,\n",
              "         -5.4923e-03, -2.0830e-02, -5.1517e-02,  7.4073e-02,  1.0159e-01,\n",
              "          2.6526e-02, -4.6871e-02, -3.0946e-02, -6.1070e-03,  4.3172e-02,\n",
              "         -8.9039e-03, -6.3156e-02,  1.2203e-02, -1.1977e-02,  1.2595e-01,\n",
              "          3.8074e-02,  5.5668e-02, -5.4720e-02, -3.3834e-02, -4.1480e-02,\n",
              "         -1.7305e-01,  3.9991e-02,  1.3082e-01, -1.3146e-03,  1.7142e-02,\n",
              "         -1.1855e-01, -2.8307e-02, -3.5841e-02,  3.7104e-02,  3.3495e-02,\n",
              "          2.4563e-02, -2.6819e-02, -2.9029e-02, -6.5953e-02,  4.8360e-02,\n",
              "         -1.4219e-01,  6.1758e-02,  5.4675e-02, -1.3479e-01, -8.2058e-02,\n",
              "          7.1276e-03,  2.8037e-02, -4.9126e-02, -7.7817e-02, -2.4360e-02,\n",
              "         -7.8810e-02,  1.4133e-03, -2.9368e-02,  2.0661e-02,  4.1818e-02,\n",
              "          8.6524e-02,  3.1389e-06,  7.0464e-02,  6.1521e-03,  2.7473e-02,\n",
              "         -4.8424e-04,  2.0300e-02,  1.1765e-01,  2.6571e-02,  5.4089e-02,\n",
              "          9.8230e-03,  1.8090e-02, -5.8735e-02,  1.9556e-02,  7.3306e-02,\n",
              "         -7.4479e-02,  2.5248e-03,  9.7351e-02, -2.3063e-02, -4.8314e-02,\n",
              "          1.3691e-02, -7.7817e-02, -1.3777e-01, -3.6563e-02,  5.6886e-02,\n",
              "         -3.7059e-02,  2.5736e-02, -4.4435e-02, -1.4553e-01, -1.9172e-02,\n",
              "         -2.8826e-02, -4.8450e-02, -5.5532e-02,  4.9668e-02,  1.1485e-01,\n",
              "          1.4041e-02, -3.6991e-02, -7.4434e-02,  4.1660e-02, -3.4933e-03,\n",
              "         -2.9728e-02, -2.2161e-02,  6.7667e-03, -2.6480e-02, -1.0177e-01,\n",
              "          6.4600e-02,  9.9877e-02,  6.2254e-02,  8.5847e-02, -8.1336e-02,\n",
              "          6.3246e-02,  1.2649e-01, -1.2158e-02, -6.1983e-02,  8.3186e-02,\n",
              "          1.8214e-03,  1.1693e-01, -6.7938e-02,  1.2413e-03,  6.7306e-02,\n",
              "          4.7006e-02,  1.9984e-02, -9.2366e-03,  2.0199e-02,  2.5849e-02,\n",
              "         -4.5833e-02, -2.2691e-02, -1.7842e-02, -6.0855e-02, -8.1291e-02,\n",
              "          5.4720e-02, -9.1035e-02,  8.8982e-03,  4.1593e-02,  1.5755e-02,\n",
              "         -3.1758e-02,  1.9804e-02,  4.6555e-02,  2.6458e-02, -1.1238e-02,\n",
              "         -8.3140e-02,  1.8947e-02,  9.5997e-02,  6.5581e-03,  4.0803e-02,\n",
              "          1.8699e-02,  6.3472e-02, -1.8349e-02, -1.7233e-02, -7.8178e-02,\n",
              "          1.8202e-02,  2.9977e-02, -4.1999e-02, -5.7472e-02, -1.1188e-01,\n",
              "         -8.6975e-02, -1.1408e-02,  9.4103e-02,  8.8419e-02,  3.7691e-02,\n",
              "          7.1502e-02,  1.4199e-02,  9.1982e-02,  1.2415e-01,  3.2435e-02,\n",
              "         -5.7607e-02, -3.8931e-02, -1.0944e-01, -8.6614e-02,  1.2649e-01,\n",
              "         -3.6788e-02,  5.9502e-02,  6.7577e-02,  6.5231e-02, -3.3540e-02,\n",
              "         -7.5068e-04], dtype=torch.float64),\n",
              " tensor([1, 0], dtype=torch.int8))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_dataset = PickleEssaysDataset(pkl_file='/content/drive/MyDrive/Diversify/synthetic_dataset.pkl')\n",
        "synthetic_dataset.__getitem__(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYQDShPEPpCj"
      },
      "source": [
        "# Sample dataset using NullLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHxCI73Vh2Qa"
      },
      "source": [
        "## Define Nulloader Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7TNXRKq5h7sy"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class NullLoader(DataLoader):\n",
        "    def __init__(self, proto_loader:DataLoader,\n",
        "                 outbatch:int, rejection_iters:int, buffer_len:int,\n",
        "                 reduced_shape:tuple[int], outshape:tuple[int],\n",
        "                 dimreduction = lambda x: x,\n",
        "                 device = 'cuda'):\n",
        "        self.proto = proto_loader\n",
        "        self.proto_batch = proto_loader.batch_size\n",
        "        self.mem = buffer_len\n",
        "        self.dimreduce = dimreduction\n",
        "        self.rdim = reduced_shape\n",
        "        self.odim = outshape\n",
        "        self.batch_size = outbatch\n",
        "        self.rejection_iters = rejection_iters\n",
        "        self.device = device\n",
        "        # assert outbatch % rejection_iters == 0, f\"must be able to make full batch in {rejection_iters} iters\"\n",
        "        # assert self.mem % self.proto_batch == 0, f\"buffer len {self.mem} must be divisible by the prototype loader batch size {self.proto_batch}\"\n",
        "        self.buffer = torch.zeros((self.mem,) + self.rdim, device=self.device)\n",
        "\n",
        "    def __iter__(self):\n",
        "        cand_labels = []\n",
        "        candidates = []\n",
        "        gradweights = []\n",
        "        top_n = self.batch_size // self.rejection_iters\n",
        "\n",
        "        for _ in range(self.rejection_iters):\n",
        "            # print(\"rejection iter\", _)\n",
        "            self._protobatch, self._protolabels = next(iter(self.proto))\n",
        "            self._protobatch, self._protolabels = self._protobatch.to(self.device), self._protolabels.to(self.device)\n",
        "            dimreduced = self.dimreduce(self._protobatch)\n",
        "\n",
        "            # Compute the SVD of the buffer\n",
        "            U, S, Vh = torch.linalg.svd(self.buffer.view((self.mem, -1)), full_matrices=False)\n",
        "\n",
        "            # Determine the rank and construct the projection matrix onto the null space\n",
        "            threshold = 1e-6\n",
        "            rank = (S > threshold).sum().item()\n",
        "            if rank == 0:\n",
        "                # The buffer is empty or has rank zero; the null space is the entire space\n",
        "                P_null = torch.eye(self.buffer.shape[1], device=self.device)\n",
        "            else:\n",
        "                V_row = Vh[:rank, :]\n",
        "                P_row = V_row.T @ V_row\n",
        "                P_null = torch.eye(P_row.shape[0], device=self.device) - P_row\n",
        "\n",
        "            # Project candidates onto the null space and compute projection errors\n",
        "            dimreduced_flat = dimreduced.view(self._protobatch.size(0), -1).T  # Shape: (n_features, batch_size)\n",
        "            projections = P_null.double() @ dimreduced_flat  # Shape: (n_features, batch_size)\n",
        "            proj_errs = torch.linalg.norm(projections, dim=0)\n",
        "\n",
        "            # Select top_n candidates with the largest projection errors\n",
        "            asort = torch.argsort(proj_errs, descending=True).to(self.device)\n",
        "            gradweights.append(proj_errs[asort])\n",
        "            candidates.append(self._protobatch[asort])\n",
        "            cand_labels.append(self._protolabels[asort])\n",
        "\n",
        "            # Update the buffer\n",
        "            self.buffer = torch.roll(self.buffer, shifts=top_n, dims=0)\n",
        "            self.buffer[:top_n] = dimreduced[asort[:top_n]].float()\n",
        "\n",
        "        # Concatenate and normalize gradweights\n",
        "        candidates = torch.cat(candidates, dim=0)\n",
        "        cand_labels = torch.cat(cand_labels, dim=0)\n",
        "        gradweights = torch.cat(gradweights, dim=0)\n",
        "        gradweights /= gradweights.sum()\n",
        "\n",
        "        yield candidates, cand_labels, gradweights, asort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl0rjXhsh_Dq"
      },
      "source": [
        "## Sample dataset using Nulloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zqwcFBFO2g8m",
        "outputId": "d3deee30-519c-4ab1-87cf-86809f61f9ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset length 296\n",
            "loader 16\n",
            "iter 0\n",
            "torch.Size([256, 256])\n",
            "torch.Size([256])\n",
            "torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "# Create a DataLoader to load the dataset in batches\n",
        "BATCH = 32\n",
        "# print(\"dataset length\", len(private_dataset))\n",
        "# control_loader = torch.utils.data.DataLoader(private_dataset, batch_size=BATCH, shuffle=True)\n",
        "# print(\"dataset length\", len(ellipse_dataset))\n",
        "# control_loader = torch.utils.data.DataLoader(ellipse_dataset, batch_size=BATCH, shuffle=True)\n",
        "print(\"dataset length\", len(synthetic_dataset))\n",
        "control_loader = torch.utils.data.DataLoader(synthetic_dataset, batch_size=BATCH, shuffle=True)\n",
        "def norm(x):\n",
        "    vnorm = torch.linalg.vector_norm(x.view(x.shape[0], -1), dim=1)\n",
        "    return x.transpose(0, -1).div(vnorm).transpose(0, -1)\n",
        "PROTOBATCH = 16\n",
        "RITERS = 8\n",
        "MEM = 256\n",
        "proto_loader = torch.utils.data.DataLoader(synthetic_dataset, batch_size=PROTOBATCH, shuffle=True)\n",
        "print(\"loader\", proto_loader.batch_size)\n",
        "exp_loader = NullLoader(control_loader, BATCH, RITERS, MEM, (256,), (256,), norm, device=\"cuda\")\n",
        "# print(exp_loader.get_scores())\n",
        "for i in range(1):\n",
        "  print(\"iter\",i)\n",
        "  candidates, lablels, weights, asort = next(iter(exp_loader))\n",
        "# for i in exp_loader:\n",
        "#   pass\n",
        "print(candidates.shape)\n",
        "print(weights.shape)\n",
        "print(asort.shape)\n",
        "\n",
        "# get top 100 essays\n",
        "selected_labels = lablels[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvLg8kgpDUm1"
      },
      "source": [
        "# (Optional) Perform K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoYR4KbBDXnL",
        "outputId": "5684f388-4feb-435c-d4cf-0db24b71841d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14\n",
            "Sampled Data Points (features, labels):\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([1, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import random\n",
        "n_clusters = 4  # Set the number of clusters as needed\n",
        "num_samples = 7 # Set number of samples\n",
        "dataset = synthetic_dataset\n",
        "dataset_length = len(dataset)\n",
        "\n",
        "assert num_samples <= dataset_length, \"Number of samples cannot exceed the dataset length\"\n",
        "\n",
        "\n",
        "# Extract features from the dataset\n",
        "features_list = []\n",
        "\n",
        "# Loop through the dataset and extract features\n",
        "for i in range(len(dataset)):\n",
        "    features, _ = dataset[i]\n",
        "    features_list.append(features.numpy())\n",
        "print(len(features_list))\n",
        "# Convert list to a NumPy array\n",
        "X = np.array(features_list)\n",
        "\n",
        "# Perform K-means clustering\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Get cluster labels for each data point\n",
        "cluster_labels = kmeans.labels_\n",
        "\n",
        "# Organize data points by clusters\n",
        "clusters = {i: [] for i in range(n_clusters)}\n",
        "\n",
        "for idx, label in enumerate(cluster_labels):\n",
        "    clusters[label].append(idx)\n",
        "\n",
        "samples_per_cluster = num_samples // n_clusters\n",
        "sampled_indices = []\n",
        "\n",
        "# Sample from each cluster\n",
        "for i in range(n_clusters):\n",
        "    cluster_size = len(clusters[i])\n",
        "    if cluster_size < samples_per_cluster:\n",
        "        sampled_indices.extend(clusters[i])  # Add all if less than needed\n",
        "    else:\n",
        "        sampled_indices.extend(random.sample(clusters[i], samples_per_cluster))\n",
        "\n",
        "while len(sampled_indices) < num_samples:\n",
        "    cluster = random.randint(0, n_clusters - 1)\n",
        "    sample = random.choice(clusters[cluster])\n",
        "    if sample not in sampled_indices:\n",
        "      sampled_indices.append(sample)\n",
        "# Get the sampled data points\n",
        "selected = [dataset[i] for i in sampled_indices]\n",
        "\n",
        "# Output the sampled data\n",
        "print(\"Sampled Data Points (features, labels):\")\n",
        "selected_labels = []\n",
        "for features, label in selected:\n",
        "    print(label)\n",
        "    selected_labels.append(label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_O3r7r42lTrv"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBy_ZIfnG2Or"
      },
      "source": [
        "## Randomly Select Labels and actual distribution as a control"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8AnDOOqG1yM",
        "outputId": "25f71ef2-1952-4d8e-a189-0c0f297f97bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([0, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([0, 1], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([1, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([1, 1], dtype=torch.int8)\n",
            "tensor([0, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([2, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([0, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([0, 0], dtype=torch.int8)\n",
            "tensor([1, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([0, 1], dtype=torch.int8)\n",
            "tensor([4, 0], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([3, 1], dtype=torch.int8)\n",
            "tensor([4, 1], dtype=torch.int8)\n",
            "tensor([1, 1], dtype=torch.int8)\n",
            "tensor([3, 0], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "num_samples = 100 # Set number of samples\n",
        "dataset = synthetic_dataset\n",
        "dataset_length = len(dataset)\n",
        "\n",
        "# Now randomly sample as a control\n",
        "sampled_indices = random.sample(range(dataset_length), num_samples)\n",
        "\n",
        "# Get the sampled data points\n",
        "randomly_selected = [dataset[i] for i in sampled_indices]\n",
        "\n",
        "randomly_selected_labels = []\n",
        "for features, label in randomly_selected:\n",
        "    print(label)\n",
        "    randomly_selected_labels.append(label)\n",
        "\n",
        "actual_labels = []\n",
        "for i in range(len(dataset)):\n",
        "    _, labels = dataset[i]\n",
        "    actual_labels.append(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0AkklZFENek"
      },
      "source": [
        "## Analyze results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W98wedZbEMMM",
        "outputId": "d2ee6c65-2ebb-4864-e01e-472b70fad080"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Selected Distribution\n",
            "Race distribution:\n",
            "Hispanic: 8.00%\n",
            "Black: 9.00%\n",
            "American Indian or Alaskan Native: 2.00%\n",
            "Asian: 49.00%\n",
            "White: 32.00%\n",
            "Gender distribution:\n",
            "Female: 53.00%\n",
            "Male: 47.00%\n",
            "\n",
            "Random Distribution\n",
            "Race distribution:\n",
            "Hispanic: 11.00%\n",
            "Black: 4.00%\n",
            "American Indian or Alaskan Native: 1.00%\n",
            "Asian: 44.00%\n",
            "White: 40.00%\n",
            "Gender distribution:\n",
            "Female: 47.00%\n",
            "Male: 53.00%\n",
            "\n",
            "Actual Distribution\n",
            "Race distribution:\n",
            "Hispanic: 10.14%\n",
            "Black: 4.73%\n",
            "American Indian or Alaskan Native: 0.68%\n",
            "Asian: 47.30%\n",
            "White: 37.16%\n",
            "Gender distribution:\n",
            "Female: 50.00%\n",
            "Male: 50.00%\n"
          ]
        }
      ],
      "source": [
        "list_to_analyze = selected_labels\n",
        "\n",
        "races = [\"Hispanic\", \"Black\", \"American Indian or Alaskan Native\", \"Asian\", \"White\"]\n",
        "genders = [\"Female\", \"Male\"]\n",
        "\n",
        "race_dict = {}\n",
        "gender_dict = {}\n",
        "\n",
        "for label in list_to_analyze:\n",
        "  race_dict[races[label[0]]] = race_dict.get(races[label[0]], 0) + 1\n",
        "  gender_dict[genders[label[1]]] = gender_dict.get(genders[label[1]], 0) + 1\n",
        "\n",
        "# print percentages\n",
        "print(\"Selected Distribution\")\n",
        "print(\"Race distribution:\")\n",
        "for race in races:\n",
        "    percentage = (race_dict.get(race,0) / len(list_to_analyze)) * 100\n",
        "    print(f\"{race}: {percentage:.2f}%\")\n",
        "\n",
        "print(\"Gender distribution:\")\n",
        "for gender in genders:\n",
        "    percentage = (gender_dict.get(gender, 0) / len(list_to_analyze)) * 100\n",
        "    print(f\"{gender}: {percentage:.2f}%\")\n",
        "\n",
        "\n",
        "random_race_dict = {}\n",
        "random_gender_dict = {}\n",
        "\n",
        "for label in randomly_selected_labels:\n",
        "  random_race_dict[races[label[0]]] = random_race_dict.get(races[label[0]], 0) + 1\n",
        "  random_gender_dict[genders[label[1]]] = random_gender_dict.get(genders[label[1]], 0) + 1\n",
        "print()\n",
        "print(\"Random Distribution\")\n",
        "print(\"Race distribution:\")\n",
        "for race in races:\n",
        "    percentage = (random_race_dict.get(race, 0) / len(randomly_selected_labels)) * 100\n",
        "    print(f\"{race}: {percentage:.2f}%\")\n",
        "\n",
        "print(\"Gender distribution:\")\n",
        "for gender in genders:\n",
        "    percentage = (random_gender_dict.get(gender, 0) / len(randomly_selected_labels)) * 100\n",
        "    print(f\"{gender}: {percentage:.2f}%\")\n",
        "\n",
        "actual_race_dict = {}\n",
        "actual_gender_dict = {}\n",
        "\n",
        "for label in actual_labels:\n",
        "  actual_race_dict[races[label[0]]] = actual_race_dict.get(races[label[0]], 0) + 1\n",
        "  actual_gender_dict[genders[label[1]]] = actual_gender_dict.get(genders[label[1]], 0) + 1\n",
        "print()\n",
        "print(\"Actual Distribution\")\n",
        "print(\"Race distribution:\")\n",
        "for race in races:\n",
        "    percentage = (actual_race_dict.get(race,0) / len(actual_labels)) * 100\n",
        "    print(f\"{race}: {percentage:.2f}%\")\n",
        "\n",
        "print(\"Gender distribution:\")\n",
        "for gender in genders:\n",
        "    percentage = (actual_gender_dict.get(gender, 0) / len(actual_labels)) * 100\n",
        "    print(f\"{gender}: {percentage:.2f}%\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBfMRntNpHNh"
      },
      "source": [
        "# Final writeup\n",
        "As you can see the results are decent. The percentage of black applicants doubled from the actual distribution, the number of white applicants decreased, and the american indian and alaskan native population despite being wildly underepresented grew by almost 4x. Unfortunately, the number of hispanics went down from the original distribution showing the algorithm isn't perfect but still has potential."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xjY3dDJjK1E4",
        "qvLg8kgpDUm1"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
